{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bebe2403",
   "metadata": {},
   "source": [
    "# Autoencoders using HE --> IHC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "343eef00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Sidra\\\\Downloads'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51fa7139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in c:\\users\\sidra\\documents\\custom office templates\\lib\\site-packages (0.20.0)\n",
      "Requirement already satisfied: numpy>=1.21.1 in c:\\users\\sidra\\documents\\custom office templates\\lib\\site-packages (from scikit-image) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.8 in c:\\users\\sidra\\documents\\custom office templates\\lib\\site-packages (from scikit-image) (1.11.1)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\sidra\\documents\\custom office templates\\lib\\site-packages (from scikit-image) (3.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in c:\\users\\sidra\\documents\\custom office templates\\lib\\site-packages (from scikit-image) (9.4.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in c:\\users\\sidra\\documents\\custom office templates\\lib\\site-packages (from scikit-image) (2.26.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\sidra\\documents\\custom office templates\\lib\\site-packages (from scikit-image) (2023.4.12)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\sidra\\documents\\custom office templates\\lib\\site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sidra\\documents\\custom office templates\\lib\\site-packages (from scikit-image) (23.1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\sidra\\documents\\custom office templates\\lib\\site-packages (from scikit-image) (0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a5d8edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd62976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the autoencoder model\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Encoder layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # Decoder layers\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260c4e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593a6aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 0.005\n",
    "\n",
    "# Image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "he_set = torchvision.datasets.ImageFolder('C:/Users/sidra/Desktop/bci/he/train', transform=transform)\n",
    "he_loader = torch.utils.data.DataLoader(he_set , batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1d4c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "\n",
    "model = Autoencoder().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a856a97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6153fe43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for he_images, _ in he_loader:\n",
    "        # Move data to the selected device\n",
    "        he_images = he_images.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(he_images)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, he_images)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    # Print the average loss for the epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40b7c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "#torch.save(model, 'autoencode_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec3adb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = image.open(\"C:/Users/sidra/Desktop/bci/he/new/00000_train_1+.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d548ba4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image2=Image.open(\"C:/Users/sidra/Desktop/bci/ihc/new/00000_train_1+.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa194a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cfe266",
   "metadata": {},
   "outputs": [],
   "source": [
    "image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ce810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f318b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr(image1, image2, max_value=1.0):\n",
    "    mse = torch.mean((image1 - image2) ** 2)\n",
    "    psnr_value = 20 * torch.log10(max_value / torch.sqrt(mse))\n",
    "    return psnr_value\n",
    "\n",
    "def ssim(image1, image2, window_size=20, sigma=1.5, data_range=1.0, k1=0.01, k2=0.03):\n",
    "    mu1 = F.avg_pool2d(image1, window_size, stride=1, padding=window_size//2)\n",
    "    mu2 = F.avg_pool2d(image2, window_size, stride=1, padding=window_size//2)\n",
    "\n",
    "    sigma1_sq = F.avg_pool2d(image1 ** 2, window_size, stride=1, padding=window_size//2) - mu1 ** 2\n",
    "    sigma2_sq = F.avg_pool2d(image2 ** 2, window_size, stride=1, padding=window_size//2) - mu2 ** 2\n",
    "    sigma12 = F.avg_pool2d(image1 * image2, window_size, stride=1, padding=window_size//2) - mu1 * mu2\n",
    "\n",
    "    c1 = (k1 * data_range) ** 2\n",
    "    c2 = (k2 * data_range) ** 2\n",
    "\n",
    "    ssim_value = ((2 * mu1 * mu2 + c1) * (2 * sigma12 + c2)) / ((mu1 ** 2 + mu2 ** 2 + c1) * (sigma1_sq + sigma2_sq + c2))\n",
    "    ssim_value = torch.mean(ssim_value)\n",
    "\n",
    "    return ssim_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e43988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "# Define the path to the directory containing the images\n",
    "img_dir = \"C:/Users/sidra/Desktop/bci/he/test/*.png\"\n",
    "#glob=global\n",
    "# Use glob to get all the image file names in the directory\n",
    "#We can use the function glob.glob() directly from glob module to retrieve paths recursively from \n",
    "#inside the directories/files and subdirectories/subfiles.\n",
    "img_files = glob.glob(img_dir)\n",
    "\n",
    "# Loop over all the image files and display them using matplotlib\n",
    "for img_file in img_files:\n",
    "    # Read the image using matplotlib.imread() function\n",
    "    img = plt.imread(img_file)\n",
    "    \n",
    "# Display the image using matplotlib.pyplot.imshow() function\n",
    "    plt.title(\"HE Images\")\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd4e6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the trained model\n",
    "# model = Autoencoder().to(device)\n",
    "# model.load_state_dict(torch.load('autoencoder_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e263d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "# Test the autoencoder using H&E test images and  generate IHC images\n",
    "test_dataset = torchvision.datasets.ImageFolder('C:/Users/sidra/Desktop/bci/he/test', transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "total_psnr = 0.0\n",
    "total_ssim = 0.0\n",
    "num_samples = 0\n",
    "\n",
    "\n",
    "for i,(he_image, _) in enumerate(test_loader):\n",
    "    # Move data to the selected device\n",
    "    he_image = he_image.to(device)\n",
    "    \n",
    "    # Perform image translation\n",
    "    ihc_image = model(he_image)\n",
    "   \n",
    "    \n",
    "    # Calculate PSNR and SSIM\n",
    "    psnr_value = psnr(ihc_image, he_image)\n",
    "    ssim_value = ssim(ihc_image, he_image)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    total_psnr += psnr_value.item()\n",
    "    total_ssim += ssim_value.item()\n",
    "    num_samples += 1\n",
    "    \n",
    "    \n",
    "    # Convert tensor to numpy array and save the generated IHC image\n",
    "    ihc_image = ihc_image.detach().cpu().numpy()\n",
    "#     # Save the generated IHC image\n",
    "#     ihc_image.save(ihc_image, 'C:/Users/PG LAB/Desktop/bci ds/full/all')\n",
    "# Convert numpy array to PIL image\n",
    "#     ihc_image = Image.fromarray((ihc_image * 255).astype(np.uint8).squeeze())\n",
    "    ihc_image = (ihc_image[0].transpose(1, 2, 0) + 1) / 2.0  # Convert from [-1, 1] to [0, 1]\n",
    "\n",
    "    # Scale the values to [0, 255]\n",
    "    ihc_image = (ihc_image * 255).astype(np.uint8)\n",
    "\n",
    "    # Convert numpy array to PIL image\n",
    "    ihc_image = Image.fromarray(ihc_image)\n",
    "\n",
    "    # Save the generated IHC image\n",
    "    ihc_image.save(f'C:/Users/sidra/Desktop/bci/newimg.png')\n",
    "    \n",
    "print(\"Autoencoder Image-to-image translation complete.\")\n",
    "average_psnr = total_psnr / num_samples\n",
    "average_ssim = total_ssim / num_samples\n",
    "print(\"Average PSNR:{:.4f}\".format(average_psnr))\n",
    "print(\"Average SSIM:{:.4f}\".format(average_ssim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870b02a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98c68c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import ToPILImage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760d8bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the tensor to a PIL image\n",
    "pil= tensor_to_pil(he_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43588a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "he_image.show()  # Display the image\n",
    "pil_image.save(\"image1.png\")  # Save the image to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2546f565",
   "metadata": {},
   "outputs": [],
   "source": [
    "ihc_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca02fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "psnr_values = []  # List to store PSNR values\n",
    "ssim_values = []  # List to store SSIM values\n",
    "\n",
    "for i,(he_image, _) in enumerate(test_loader):\n",
    "    # Move data to the selected device\n",
    "    he_image = he_image.to(device)\n",
    "    \n",
    "    # Perform image translation\n",
    "    ihc_image = model(he_image)\n",
    "    \n",
    "    # Calculate PSNR and SSIM\n",
    "    psnr_value = psnr(ihc_image, he_image)\n",
    "    ssim_value = ssim(ihc_image, he_image)\n",
    "\n",
    "    \n",
    "    # Append PSNR and SSIM values to the respective lists\n",
    "    psnr_values.append(psnr_value.item())\n",
    "    ssim_values.append(ssim_value.item())\n",
    "\n",
    "# Convert the lists to NumPy arrays\n",
    "psnr_values = np.array(psnr_values)\n",
    "ssim_values = np.array(ssim_values)\n",
    "\n",
    "# Generate x-axis values\n",
    "x = np.arange(1, num_samples + 1)\n",
    "\n",
    "# Plot the PSNR values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x, psnr_values, label='PSNR')\n",
    "plt.xlabel('Image')\n",
    "plt.ylabel('PSNR')\n",
    "plt.title('PSNR values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot the SSIM values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x, ssim_values, label='SSIM')\n",
    "plt.xlabel('Image')\n",
    "plt.ylabel('SSIM')\n",
    "plt.title('SSIM values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b961af28",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'autoencodernew_model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f686c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('autoencodernew_model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fefa405",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85c56cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
